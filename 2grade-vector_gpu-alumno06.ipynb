{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3431319e-2e6b-43c1-a2f6-61ccba592c21",
   "metadata": {},
   "source": [
    "## Evaluating a vectorial function on CPU and GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d142183-b6bb-42e7-ba9d-35bf0f91dc0c",
   "metadata": {},
   "source": [
    "### CPU: plain and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b92dd336-9997-4323-80e4-f285e9cc2db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "8.44 ms ± 97 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "18.4 ms ± 34.3 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "18.4 ms ± 27 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit, jit\n",
    "\n",
    "# Python plain implementation w/ numba \n",
    "@njit\n",
    "def grade2_vector(x, y, a, b, c):\n",
    "    z = np.zeros(x.size)\n",
    "    for i in range(x.size):\n",
    "        z[i] = a*x[i]*x[i] + b*y[i] + c\n",
    "    return z\n",
    "\n",
    "# Numpy ufunc\n",
    "def grade2_ufunc(x, y, a, b, c):\n",
    "    return a*x**2 + b*y + c\n",
    "\n",
    "# size of the vectors\n",
    "size = 5_000_000\n",
    "\n",
    "# allocating and populating the vectors\n",
    "a_cpu = np.random.rand(size)\n",
    "b_cpu = np.random.rand(size)\n",
    "c_cpu = np.zeros(size)\n",
    "\n",
    "a = 3.5\n",
    "b = 2.8\n",
    "c = 10\n",
    "\n",
    "# Printing input values\n",
    "#print(a_cpu)\n",
    "#print(b_cpu)\n",
    "# Random function in Numpy always use float64\n",
    "print(a_cpu.dtype)\n",
    "\n",
    "c_cpu = grade2_vector(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "\n",
    "# Evaluating the time\n",
    "\n",
    "# Numba Python: huge improvement, better that numpy code\n",
    "%timeit -n 5 -r 2 grade2_vector(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "# w/ a numpy ufunc manually coded\n",
    "%timeit -n 5 -r 2 grade2_ufunc(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "# using the general numpy ufunc \n",
    "%timeit -n 5 -r 2 a*a_cpu**2 + b*b_cpu + c\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0987caa7-d49b-45f1-b42e-53f66ee56c1c",
   "metadata": {},
   "source": [
    "# 3.2 a) Librería Cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9653ec2-fe94-4cf9-8264-9e32644dd33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Benchmarking CuPy (N=5000000) ---\n",
      "\n",
      "1. Medición SIN copia de datos (Datos ya en GPU):\n",
      "grade2_ufunc        :    CPU:   100.920 us   +/- 10.565 (min:    93.750 / max:   129.815) us     GPU-0:   900.435 us   +/-  4.134 (min:   896.896 / max:   912.384) us\n",
      "\n",
      "2. Medición CON copia de datos (Incluye transferencia CPU->GPU):\n",
      "grade2_with_copy    :    CPU:  3478.112 us   +/- 83.248 (min:  3372.638 / max:  3608.178) us     GPU-0:  5781.011 us   +/- 83.061 (min:  5664.768 / max:  5910.528) us\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "from cupyx.profiler import benchmark \n",
    "\n",
    "# 1. Definimos la función matemática (ufunc)\n",
    "def grade2_ufunc(x, y, a, b, c):\n",
    "    return a * x**2 + b * y + c\n",
    "\n",
    "# Parámetros del ejercicio\n",
    "size = 5_000_000\n",
    "a, b, c = 3.5, 2.8, 10.0\n",
    "\n",
    "print(f\"--- Benchmarking CuPy (N={size}) ---\\n\")\n",
    "\n",
    "# ==========================================\n",
    "# CASO A: SIN COPIA (Datos creados en GPU)\n",
    "# ==========================================\n",
    "# Creamos los arrays directamente en la VRAM de la GPU\n",
    "x_gpu = cp.random.rand(size, dtype=cp.float32)\n",
    "y_gpu = cp.random.rand(size, dtype=cp.float32)\n",
    "\n",
    "print(\"1. Medición SIN copia de datos (Datos ya en GPU):\")\n",
    "# benchmark ejecuta la función varias veces y devuelve estadísticas\n",
    "result_no_copy = benchmark(grade2_ufunc, (x_gpu, y_gpu, a, b, c), n_repeat=10)\n",
    "print(result_no_copy)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# CASO B: CON COPIA (CPU -> GPU -> Cálculo)\n",
    "# ==========================================\n",
    "# Creamos los arrays en la RAM de la CPU (NumPy)\n",
    "x_cpu = np.random.rand(size).astype(np.float32)\n",
    "y_cpu = np.random.rand(size).astype(np.float32)\n",
    "\n",
    "# Definimos una función envoltorio que incluya la transferencia explícita\n",
    "# para que el benchmark mida también el tiempo de mover los datos.\n",
    "def grade2_with_copy(x, y, a, b, c):\n",
    "    x_d = cp.asarray(x) # Copia CPU -> GPU\n",
    "    y_d = cp.asarray(y) # Copia CPU -> GPU\n",
    "    return a * x_d**2 + b * y_d + c\n",
    "\n",
    "print(\"\\n2. Medición CON copia de datos (Incluye transferencia CPU->GPU):\")\n",
    "result_copy = benchmark(grade2_with_copy, (x_cpu, y_cpu, a, b, c), n_repeat=10)\n",
    "print(result_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21e8c49-617f-4128-8127-79245cd25882",
   "metadata": {},
   "source": [
    "# 3.2. b) Librería Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68a5db9f-cdc6-4bd9-aaed-24c5a1386602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Benchmarking Numba CUDA (N=5000000) ---\n",
      "\n",
      "1. Medición SIN copia (usando arrays ya en GPU):\n",
      "grade2_numba        :    CPU:  1505.309 us   +/- 700.690 (min:   840.425 / max:  2399.791) us     GPU-0:  1641.728 us   +/- 596.791 (min:  1065.792 / max:  2408.448) us\n",
      "\n",
      "2. Medición CON copia (pasando arrays de NumPy):\n",
      "grade2_numba        :    CPU:  9168.472 us   +/- 1394.156 (min:  7259.503 / max: 11444.168) us     GPU-0:  9175.901 us   +/- 1395.124 (min:  7266.080 / max: 11455.168) us\n"
     ]
    }
   ],
   "source": [
    "from numba import vectorize, cuda, float32\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "from cupyx.profiler import benchmark\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Definición del Kernel con Numba\n",
    "# ---------------------------------------------------------\n",
    "# Usamos el decorador @vectorize para crear una ufunc que corra en GPU (target='cuda').\n",
    "# Firma: devuelve float32, recibe 5 argumentos float32.\n",
    "@vectorize(['float32(float32, float32, float32, float32, float32)'], target='cuda')\n",
    "def grade2_numba(x, y, a, b, c):\n",
    "    return a * x**2 + b * y + c\n",
    "\n",
    "# Parámetros iniciales\n",
    "size = 5_000_000\n",
    "a, b, c = 3.5, 2.8, 10.0\n",
    "\n",
    "print(f\"--- Benchmarking Numba CUDA (N={size}) ---\\n\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Preparación de datos (CPU y GPU)\n",
    "# ---------------------------------------------------------\n",
    "# Datos en Host (CPU) para el caso \"CON COPIA\"\n",
    "x_cpu = np.random.rand(size).astype(np.float32)\n",
    "y_cpu = np.random.rand(size).astype(np.float32)\n",
    "\n",
    "# Datos en Device (GPU) para el caso \"SIN COPIA\"\n",
    "# Copiamos manualmente fuera del bucle de medición\n",
    "x_device = cuda.to_device(x_cpu)\n",
    "y_device = cuda.to_device(y_cpu)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Medición: Caso SIN COPIA (Datos residentes en VRAM)\n",
    "# ---------------------------------------------------------\n",
    "print(\"1. Medición SIN copia (usando arrays ya en GPU):\")\n",
    "# Al pasarle 'x_device' (que es un puntero a GPU), Numba detecta que no hace falta copiar.\n",
    "# Importante: benchmark() ejecuta la función repetidas veces para sacar estadísticas.\n",
    "res_no_copy = benchmark(grade2_numba, (x_device, y_device, a, b, c), n_repeat=10)\n",
    "print(res_no_copy)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. Medición: Caso CON COPIA (Transferencia automática)\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n2. Medición CON copia (pasando arrays de NumPy):\")\n",
    "# Al pasarle 'x_cpu' (NumPy), Numba hace automáticamente: Host -> Device -> Compute -> Host\n",
    "res_with_copy = benchmark(grade2_numba, (x_cpu, y_cpu, a, b, c), n_repeat=10)\n",
    "print(res_with_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a45878d-ac28-479b-aa07-8325a4dd46f7",
   "metadata": {},
   "source": [
    "# 3.2. c) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031399c6-4ceb-42ef-ae3f-6f8a09e10133",
   "metadata": {},
   "source": [
    "1. La conclusión al comparar los casos \"con Copia\" y \"sin Copia\" en ambas librerías es el coste masivo de mover datos.\n",
    "\n",
    "- Sin Copia (Datos en GPU): Cuando los datos ya residen en la memoria de la GPU (VRAM), el tiempo de ejecución es del orden de microsegundos (μs). Esto se debe a que la GPU tiene un ancho de banda de memoria extremadamente alto (cientos de GB/s) y miles de núcleos procesando en paralelo.\n",
    "\n",
    "- Con Copia (CPU ↔ GPU): Al incluir la transferencia, el tiempo aumenta drásticamente (a milisegundos). Esto demuestra que el bus PCIe actúa como un cuello de botella significativo .\n",
    "\n",
    "La estrategia óptima es mantener los datos en la GPU el mayor tiempo posible.\n",
    "\n",
    "2. Análisis de CuPy: se comporta como un \"espejo\" de NumPy. Al usar cp.asarray, forzamos la copia explicita.\n",
    "\n",
    "En el caso \"sin Copia\", CuPy es extremadamente rápido porque lanza kernels pre-compilados y optimizados para operaciones vectoriales básicas. Sin embargo, para fórmulas complejas, CuPy podría generar arrays temporales intermedios en la VRAM, lo cual consume más memoria y ancho de banda que un kernel fusionado.\n",
    "\n",
    "3. Análisis de Numba: Numba @vectorize compila la función Python a un kernel CUDA nativo.\n",
    "\n",
    "Numba es inteligente detectando el tipo de entrada. Si recibe arrays de NumPy, realiza la copia implícita (Host → Device → Host), penalizando el rendimiento igual que en el caso de CuPy con copia. Si recibe punteros de dispositivo (cuda.to_device), ejecuta a velocidad nativa.\n",
    "\n",
    "A diferencia de CuPy (que llama a kernels separados para suma, multiplicación, potencia), Numba fusiona toda la operación a*x**2 + b*y + c en un solo kernel. Esto significa que cada elemento se lee de memoria una sola vez, se opera y se escribe una sola vez.\n",
    "\n",
    "Teóricamente, Numba \"Sin Copia\" debería ser ligeramente más eficiente en uso de memoria y caché que CuPy para operaciones encadenadas, aunque ambos son órdenes de magnitud más rápidos que la CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8021e4-61fb-4e67-981f-7ecc74cf2493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
